\chapter{针对条件扩散模型的高效图像修复算法}
\section{本章引言}
本章深入探讨图像修复问题，并成功设计出算法\ref{ours algorithm}以应对线性假噪算子下的图像修复挑战。该算法在\cite{Inverse}提出的后验估计思想基础上进行了创新，充分利用线性算子和高斯分布的特性，进一步提升了后验估计的效率和准确性。同时，结合DDPM采样方法，我们采纳了\cite{DDIM}中的分段采样技术，从而显著提升了图像生成的效率。此外，我们还解决了\cite{Inverse}中提到的针对不同数据集需要手动调整逆向生成迭代学习率的难题。通过采用本文提出的算法，我们能够在不同数据集下以相对稳定的学习率实现图像还原，大大提高了算法的实用性和通用性。

\section{算法设计}
\subsection{后验估计}
通常为了获得后验证估计$p(y\mid x_t)$，我们可以将该条件概率分布写为如下形式
\begin{equation}
    p(y\mid x_t) = \int_{\mathbb{R}^n} p(x_0\mid x_t) p(y\mid x_0,x_t) dx_0,
\end{equation}
我们如果从以下角度来思考本问题，即通过逆向随机微分方程(\ref{reverse SDE conditional})先从$x_t$可以得到$x_0$， 再通过前向加噪模型(\ref{Forward model})得到$y$。根据以上模型的Markov性质可以得到
\begin{equation}
     p(y\mid x_0,x_t) = p(y\mid x_0).
\end{equation}
因此我们可以得到
\begin{equation}
    p(y\mid x_t) = \int_{\mathbb{R}^n} p(x_0\mid x_t) p(y\mid x_0) dx_0=\mathbb{E}\left[p(y\mid x_0)\mid x_t\right],
    \label{conditional posterior formula}
\end{equation}
在\cite{Inverse}中直接采用将$\hat{x}_0=\mathbb{E}\left[x_0\mid x_t\right]$带入\ref{conditional posterior formula}用来逼近真实的后验概率分布，而此逼近方法取决于前向加噪算子$H(\cdot)$的光滑性，以及随着$x$的维数上升其逼近效果也在逐渐下降，因此本文中采用更加精确的后验估计方法进行图像还原。     


为了得到对后验概率分布$p(y\mid x_t)$的逼近，根据\cite{pseudoinverse,ddrm}中的结论，通常可以假设条件可以分布$p(x_0\mid x_t)$可以用$\mathcal{N}(\hat{x}_0(x_t);\gamma_t^2 I)$
来逼近，其中$\gamma_t^2 = \frac{\sigma_t^2}{1+\sigma_t^2}$。则我们可以重新用$x_t$来表示$x_0$。我们可以把$x_0$ 用$\hat{x}_0(x_t) + \gamma \epsilon$ 来逼近，其中我们有$\epsilon\sim \mathcal{N}(0,I)$为服从标准高斯分布的随机变量。 在只考虑$\mathcal{H}$为线性算子的情形下，我们将$y$表示为
\begin{equation}
    y=H(x_0)+n = H(\hat{x}_0+\gamma_t \epsilon)+n = H\hat{x}_0 + (H\epsilon+n).
\end{equation}
根据高斯分布随机变量的可叠加性，$(H\epsilon+n)$仍为高斯分布随机变量，其分布可以表示为$\mathcal{N}(0,\gamma_t^2 H^{\top}H + \sigma_y^2 I)$。因此我们最后可以将$\nabla_{x_t}\log(p(y\mid x_t))$写为
\begin{equation}
  -\frac{1}{2} \nabla_{x_t} \bigg((H\hat{x}_0-y)^{\top}\left(\gamma_t^2 H^{\top}H + \sigma_y^2 I\right)^{-1}(H\hat{x}_0-y)\bigg),
\end{equation}
利用链式法则和线性算子的性质，最后可以将$\nabla_{x_t}\log(p(y\mid x_t))$写为
\begin{equation}
    -\left(\gamma_t^2 H^{\top}H + \sigma_y^2 I\right)^{-1}(H\hat{x}_0-y)\frac{\partial \hat{x}_0(x_t)}{\partial x_t}.
\end{equation}

\subsection{更新迭代过程}
在\cite{Inverse}中使用如下算法来进行更新迭代，最后得到$\hat{x}_0$作为对原始图像的逼近。在每一步更新迭代中，采用两步进行。第一步，先利用预训练集得到在原始无条件分布下的score function，从而得到在无条件生成通过DDPM采样更新得到的$x_{i-1}^{\prime}$以及得到$\hat{x}_0$。 第二步， 得到通过$\nabla_{x_i}\log(y\mid \hat{x}_0)$来更新$x_{i-1}^{\prime}$得到$x_{i-1}$。具体算法流程图如下算法\ref{DPS algorithm }可见
\begin{breakablealgorithm}
\caption{DPS Algorithm }
\label{DPS algorithm }
    \begin{algorithmic}[1]
   \REQUIRE Input $N$, $y$, $\{\zeta_i\}_{i=1}^{N}$, $\{\Tilde{\sigma}_i\}_{i=1}^{T}$
   \STATE $X_{T}\sim \mathcal{N}(0,\boldsymbol{I})$
   \FOR{$i$ = $N$ to 0}
   \STATE Set $\hat{s}\xleftarrow{} s_{\theta}(x_i,i)$
   \STATE Set $\hat{x_0} \xleftarrow{} \frac{1}{\sqrt{\Bar{\alpha}_i}}\left(x_i+(1-\Bar{\alpha}_i)\hat{s}\right)$
   \STATE Simulate $z\sim \mathcal{N}(0,\boldsymbol{I})$
   \STATE Set $x^{\prime}_{i-1}\xleftarrow{} \frac{\sqrt{\alpha_i}\left(1-\bar{\alpha}_{i-1}\right)}{1-\bar{\alpha}_i} \boldsymbol{x}_i+\frac{\sqrt{\bar{\alpha}_{i-1}} \beta_i}{1-\bar{\alpha}_i} \hat{\boldsymbol{x}}_0+\Tilde{\sigma}_i {z} $
   \STATE Update $x_{i-1}\xleftarrow{} {x}_{i-1}^{\prime}-\zeta_i \nabla_{{x}_t}\left\|{y}-\mathcal{A}\left(\hat{{x}}_0\right)\right\|_2^2 $
   \ENDFOR
   \RETURN $\hat{x}_0$ 
    \end{algorithmic}
\end{breakablealgorithm}      

两步迭代主要利用了在条件生成下的逆向随机微分方程的结构
\begin{equation}
    dx = \left(f(x,t) - g^2(t)(\nabla_{x_t}\log(p(x_t)))+ \nabla_{x_t}\log(y\mid x(t))\right)+g(t)d\Tilde{w}.
\end{equation}
第一步先更新除了带$\nabla_{x_t}\log(y\mid x(t))$的项，接下来再单独更新$\nabla_{x_t}\log(y\mid x(t))$的项。理论上$\nabla_{x_t}\log(y\mid x(t))$可以写为$-\frac{1}{\sigma_y^2}\nabla_{x_t}\|y-H(\hat{x}_0(x_t))\|_2^2$的形式，但是为了保证稳定性常常需要再前面乘以一个步长$\zeta_t$来保证收敛性，而在\cite{Inverse}中该步长为根据数据集本身形式人工选取，具有不稳定性和一定的随机性，不一定为最优的参数选取。如果$\sigma_y$过大则会导致每次更新步长多大如果$\sigma_y$过小则会导致每次更新步长不明显，最终生成的图片不一定能够对应损坏图片。因此在本文中采取如下方法，我们首先对应每次更新$\nabla_{x_t}\log(y\mid x(t))$项的时候的步长设置为$\eta_i$， 以及我们从$x_{i-1}^{\prime}$生成$x_{i-1}$的时候采用如下生成方式
\begin{equation}
    x_{i-1} \xleftarrow{} x_{i-1}^{\prime} - \eta_i \nabla_{x_i}\sqrt{((H\hat{x}_0-y)^{\top}\left(\gamma_i^2 H^{\top}H + \sigma_y^2 I\right)^{-1}(H\hat{x}_0-y)\bigg)}.
\end{equation}
该方法的优势在于不需要对步长刻意设置，我们在本模型中直接取$\eta_i=1$, $i=1,2,\cdots,T$， 也具有较好的稳定性。 如果直接取所有$\gamma_i=0$, $i=1,2,\cdots, T$, 则该更新方法可以写为
\begin{equation}
       x_{i-1} \xleftarrow{} x_{i-1}^{\prime} - \eta_i \nabla_{x_i}\|y-H(\hat{x}_0)\|_2,
\end{equation}
对右式继续进行化简可得
\begin{align}
    x_{i-1}^{\prime} - \eta_i \nabla_{x_i}\|y-H(\hat{x}_0)\|_2 &=  x_{i-1}^{\prime} - \frac{\eta_i}{\|y-H(\hat{x}_0)\|_2} H^{\top}(H\hat{x}_0-y)\frac{\partial \hat{x}_0}{\partial x_i}\\
    & = x_{i-1}^{\prime} - {\eta_i} H^{\top}\frac{(H\hat{x}_0-y)}{\|H\hat{x}_0-y\|_2}\frac{\partial \hat{x}_0}{\partial x_i},
\end{align}
中间的第二项里面的$\frac{(H\hat{x}_0-y)}{\|H\hat{x}_0-y\|_2}$已经被标注化，从而$\eta_i$可以控制每次更新的幅度，在原来的算法中如果仅仅对$\nabla_{x_i}\|H\hat{x}_0-y\|_2^2$进行步长选取，当$\|H\hat{x}_0-y\|$ 已经足够小的时候则不再更新，可能会陷入局部最优的解。（例如最后得到的还原图像确实经过加噪模型可以得到损坏图像，但是与原图像有较大的区别）经过实验该更新方法也确实有更好的鲁棒性。 

\subsection{算法流程}
基于DPS算法，我们现在提出我们采用更高效率基于DDIM模型的算法。在本文的改进算法中，可以采用DDPM模型进行采样，也可以对DDPM的模型中的总步长进行分割进行切片采样。进一步，还可以利用DDIM方法来进行采样，原先使用DDPM采样方法需要进行1000步，在DDIM方法下只需要100步就可以获得质量相似的图像。本文所提出的算法流程图如下所示

\begin{breakablealgorithm}
\caption{Image Restoration Algorithm }
\label{ours algorithm }
    \begin{algorithmic}[1]
   \REQUIRE Input $T$, $y$, $\{\eta_k\}_{k=1}^{T}$, $\{\sigma_k\}_{k=1}^{T}$
   \REQUIRE Choose $\{\tau_k\}_{k=1}^{m}$ according to the sampling scheme
   \STATE $X_{T}\sim \mathcal{N}(0,\boldsymbol{I})$
   \FOR{$t=m$, $m-1$, $\cdots$, $0$}
   \STATE Set $\hat{s}\xleftarrow{} s_{\theta}(\tau_t,x_{\tau_t})$
   \STATE Set $\hat{x_0} \xleftarrow{} \frac{1}{\sqrt{\Bar{\alpha}_{\tau_t}}}\left(x_{\tau_t}+\Bar{\beta}_{\tau_t}\hat{s}\right)$
   \STATE Simulate $z\sim \mathcal{N}(0,\boldsymbol{I})$
   \STATE Set $x^{\prime}_{\tau_{t-1}}\xleftarrow{} \frac{\sqrt{\alpha_{\tau_t}}\left(1-\bar{\alpha}_{\tau_{t-1}}\right)}{1-\bar{\alpha}_{\tau_t}} \boldsymbol{x}_{\tau_t}+\frac{\sqrt{\bar{\alpha}_{\tau_{t-1}}} \beta_{\tau_t}}{1-\bar{\alpha}_{\tau_t}} \hat{\boldsymbol{x}}_0+\sigma_{y} {z} $
   \STATE Update $x_{\tau_{t-1}}\xleftarrow{} {x}_{\tau_{t-1}}^{\prime}-\eta_t \sigma_y \nabla_{x_{\tau_t}}\sqrt{((H\hat{x}_0-y)^{\top}\left(\gamma_{\tau_t}^2 H^{\top}H + \sigma_y^2 I\right)^{-1}(H\hat{x}_0-y)\bigg)}$
   \ENDFOR
   \RETURN $\hat{x}_0$ 
    \end{algorithmic}
\end{breakablealgorithm}

\input{data/experiment}









\section{本章小结}
经过对图像修复领域的广泛研究和深入分析，本章所设计的算法\ref{ours algorithm }不仅解决了线性假噪算子作用下的图像修复难题，更在多个方面展现出了其独特的优势和创新性。    




首先，算法\ref{ours algorithm }在继承传统后验估计方法的基础上，进行了深入的优化和扩展。传统的后验估计方法如\cite{Inverse}虽然在一定程度上能够实现图像的修复，但往往受到诸多限制，如计算复杂度高、修复效果不稳定等。而我们的算法充分结合了线性算子和高斯分布的性质，提出了一种更为高效、更为准确的后验估计算法。这一创新使得算法在修复过程中能够更准确地捕捉图像的细节信息，从而得到更加真实、自然的修复结果。   


在算法实现过程中，我们巧妙地将DDPM（去噪扩散概率模型）采样方法与\cite{DDIM}中的分段采样策略相结合。DDPM作为一种先进的图像生成技术，其采样过程往往需要大量的计算资源和时间。而通过将DDPM与分段采样策略相结合，我们的算法能够在保证修复效果的同时，大大提高图像生成的效率。这种结合不仅优化了算法的运算流程，还使得算法在处理大规模图像或高分辨率图像时能够保持稳定的性能和高效的生成速度。     


此外，针对\cite{Inverse}中存在的迭代学习率调整问题，我们进行了深入的探究和改进。迭代学习率的调整对于算法的收敛速度和修复效果具有重要影响。通过优化算法结构和参数设置，我们成功使得算法能够在不同的数据集下以较为稳定的学习率进行图像还原。这一改进不仅提高了算法的通用性和稳定性，还使得算法能够更好地适应各种复杂的图像修复场景。     


为了验证算法的有效性和实用性，我们在LSUN和FFHQ等多个大型数据集上进行了全面的实验测试。实验结果表明，我们的算法在这些数据集上均取得了优异的图像生成效果。无论是在细节保留、色彩还原还是整体视觉效果方面，我们的算法都展现出了明显的优势。这些实验结果不仅充分验证了算法的高效性和准确性，也进一步证明了算法在不同数据集下的稳定性和通用性。    


除了实验验证外，我们还对算法进行了深入的理论分析和讨论。我们探讨了算法中各个参数对修复效果的影响，并分析了算法在不同应用场景下的适用性和局限性。这些分析和讨论不仅为我们进一步优化算法提供了指导，也为后续研究者在该领域的研究提供了有价值的参考。     


综上所述，本章所设计的算法\ref{ours algorithm }在图像修复领域展现出了卓越的性能和实用性。它不仅解决了传统算法在修复效果、计算效率等方面的不足，还在多个方面进行了创新和改进。这一创新算法为图像修复领域提供了新的思路和方法，对于推动该领域的进一步发展具有重要的意义。未来，我们将继续深入研究和优化算法，以期在图像修复领域取得更多的突破和进展。